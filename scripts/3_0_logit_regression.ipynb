{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../data/output/development_sample_cleaned_1.csv')\n",
    "df_test=pd.read_csv('../data/output/testing_sample_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35700 entries, 0 to 35699\n",
      "Data columns (total 46 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   working_months  35700 non-null  float64\n",
      " 1   ID              35700 non-null  int64  \n",
      " 2   customer_id     35700 non-null  int64  \n",
      " 3   _r_             35700 non-null  float64\n",
      " 4   Var1            35700 non-null  int64  \n",
      " 5   Var4            35700 non-null  int64  \n",
      " 6   Var5            35700 non-null  int64  \n",
      " 7   Var6            35700 non-null  int64  \n",
      " 8   Var7            35700 non-null  float64\n",
      " 9   Var15           35700 non-null  int64  \n",
      " 10  Var16           35700 non-null  int64  \n",
      " 11  Var17           35700 non-null  float64\n",
      " 12  Var20           35700 non-null  int64  \n",
      " 13  Var21           35700 non-null  int64  \n",
      " 14  Var22           35700 non-null  int64  \n",
      " 15  Var23           35700 non-null  int64  \n",
      " 16  Var24           35700 non-null  int64  \n",
      " 17  Var25           35700 non-null  float64\n",
      " 18  Var26           35700 non-null  float64\n",
      " 19  Var29           35700 non-null  int64  \n",
      " 20  Var30           35700 non-null  int64  \n",
      " 21  income          35700 non-null  int64  \n",
      " 22  target          35700 non-null  float64\n",
      " 23  Var27           35700 non-null  int64  \n",
      " 24  Var28           35700 non-null  int64  \n",
      " 25  Var2_2.0        35700 non-null  int64  \n",
      " 26  Var2_3.0        35700 non-null  int64  \n",
      " 27  Var3_2.0        35700 non-null  int64  \n",
      " 28  Var3_3.0        35700 non-null  int64  \n",
      " 29  Var11_2         35700 non-null  int64  \n",
      " 30  Var11_3         35700 non-null  int64  \n",
      " 31  Var11_4         35700 non-null  int64  \n",
      " 32  Var11_5         35700 non-null  int64  \n",
      " 33  Var11_6         35700 non-null  int64  \n",
      " 34  Var11_7         35700 non-null  int64  \n",
      " 35  Var12_2.0       35700 non-null  int64  \n",
      " 36  Var12_3.0       35700 non-null  int64  \n",
      " 37  Var12_4.0       35700 non-null  int64  \n",
      " 38  Var12_5.0       35700 non-null  int64  \n",
      " 39  Var12_6.0       35700 non-null  int64  \n",
      " 40  Var12_7.0       35700 non-null  int64  \n",
      " 41  Var12_8.0       35700 non-null  int64  \n",
      " 42  Var14_1         35700 non-null  int64  \n",
      " 43  Var14_2         35700 non-null  int64  \n",
      " 44  Var14_3         35700 non-null  int64  \n",
      " 45  Var14_4         35700 non-null  int64  \n",
      "dtypes: float64(7), int64(39)\n",
      "memory usage: 12.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3546 entries, 0 to 3545\n",
      "Data columns (total 46 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   working_months  3546 non-null   float64\n",
      " 1   ID              3546 non-null   int64  \n",
      " 2   customer_id     3546 non-null   int64  \n",
      " 3   _r_             3546 non-null   float64\n",
      " 4   Var1            3546 non-null   int64  \n",
      " 5   Var4            3546 non-null   int64  \n",
      " 6   Var5            3546 non-null   int64  \n",
      " 7   Var6            3546 non-null   int64  \n",
      " 8   Var7            3546 non-null   float64\n",
      " 9   Var15           3546 non-null   int64  \n",
      " 10  Var16           3546 non-null   int64  \n",
      " 11  Var17           3546 non-null   float64\n",
      " 12  Var20           3546 non-null   int64  \n",
      " 13  Var21           3546 non-null   int64  \n",
      " 14  Var22           3546 non-null   int64  \n",
      " 15  Var23           3546 non-null   int64  \n",
      " 16  Var24           3546 non-null   int64  \n",
      " 17  Var25           3546 non-null   float64\n",
      " 18  Var26           3546 non-null   float64\n",
      " 19  Var29           3546 non-null   int64  \n",
      " 20  Var30           3546 non-null   int64  \n",
      " 21  income          3546 non-null   int64  \n",
      " 22  target          3546 non-null   float64\n",
      " 23  Var27           3546 non-null   int64  \n",
      " 24  Var28           3546 non-null   int64  \n",
      " 25  Var2_2.0        3546 non-null   int64  \n",
      " 26  Var2_3.0        3546 non-null   int64  \n",
      " 27  Var3_2.0        3546 non-null   int64  \n",
      " 28  Var3_3.0        3546 non-null   int64  \n",
      " 29  Var11_2         3546 non-null   int64  \n",
      " 30  Var11_3         3546 non-null   int64  \n",
      " 31  Var11_4         3546 non-null   int64  \n",
      " 32  Var11_5         3546 non-null   int64  \n",
      " 33  Var11_6         3546 non-null   int64  \n",
      " 34  Var11_7         3546 non-null   int64  \n",
      " 35  Var12_2.0       3546 non-null   int64  \n",
      " 36  Var12_3.0       3546 non-null   int64  \n",
      " 37  Var12_4.0       3546 non-null   int64  \n",
      " 38  Var12_5.0       3546 non-null   int64  \n",
      " 39  Var12_6.0       3546 non-null   int64  \n",
      " 40  Var12_7.0       3546 non-null   int64  \n",
      " 41  Var12_8.0       3546 non-null   int64  \n",
      " 42  Var14_1         3546 non-null   int64  \n",
      " 43  Var14_2         3546 non-null   int64  \n",
      " 44  Var14_3         3546 non-null   int64  \n",
      " 45  Var14_4         3546 non-null   int64  \n",
      "dtypes: float64(7), int64(39)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35184372088832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Istnieje teoretycznie 2^45 mozliwych modeli z roznymi parametrami ktore mozemy uzyskac z tego zestawu danych\n",
    "# A więc istnieje 35184372088832\n",
    "# Jest to 35 trylionów możliwych modeli \n",
    "2**45\n",
    "# Przy zalozeniu ze wykorzystalbym wszystkie moce swojego kompa 6-rdzeniowemu komputerowi z maksymalnym taktowaniem 3.6 GHz i 16 GB RAM o szybkości 2667 MHz \n",
    "# 2^45sekund=35,184,372,088,832 sekund\n",
    "# to jest około 185 lat XDDDDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_balanced_data(df, ratio):\n",
    "    df_majority = df[df.target == 0]\n",
    "    df_minority = df[df.target == 1]\n",
    "    n_samples = int(len(df_minority) * ratio) if ratio <= len(df_majority) / len(df_minority) else len(df_majority)\n",
    "    df_majority_downsampled = resample(df_majority, replace=False, n_samples=n_samples, random_state=123)\n",
    "    return pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Funkcja do trenowania modelu i obliczania metryk\n",
    "def train_evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 48) (1690481538.py, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 48\u001b[1;36m\u001b[0m\n\u001b[1;33m    ''''''''''\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 48)\n"
     ]
    }
   ],
   "source": [
    "'''''''''\n",
    "\n",
    "\n",
    "scalers = {\"standard\": StandardScaler(), \"min_max\": MinMaxScaler(), \"robust\": RobustScaler(), \"none\": None}\n",
    "best_models = {}\n",
    "\n",
    "# Iterowanie przez wszystkie skalery i różne proporcje downsamplingu i podziału zbioru treningowego\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    best_score = 0\n",
    "    for downsample_ratio in [0.5, 1, 2, 3]:\n",
    "        df_train_balanced = prepare_balanced_data(df_train, downsample_ratio)\n",
    "        for split_ratio in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "            X = df_train_balanced.drop('target', axis=1)\n",
    "            y = df_train_balanced['target']\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_ratio, random_state=42)\n",
    "\n",
    "            # Skalowanie danych, jeśli scaler jest zdefiniowany\n",
    "            if scaler:\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                X_test_scaled = scaler.transform(df_test.drop('target', axis=1))\n",
    "            else:\n",
    "                X_train_scaled = X_train\n",
    "                X_val_scaled = X_val\n",
    "                X_test_scaled = df_test.drop('target', axis=1)\n",
    "\n",
    "            # Trenowanie i ewaluacja modelu na zbiorze walidacyjnym\n",
    "            metrics = train_evaluate_model(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "            if metrics['f1_score'] > best_score:\n",
    "                best_score = metrics['f1_score']\n",
    "                best_models[scaler_name] = (LogisticRegression(max_iter=1000).fit(X_train_scaled, y_train), scaler, downsample_ratio, split_ratio)\n",
    "\n",
    "# Dla każdego skalera, trenowanie najlepszego modelu na pełnym zbiorze treningowym i ewaluacja na zbiorze testowym\n",
    "final_results = {}\n",
    "for scaler_name, (model, scaler, downsample_ratio, split_ratio) in best_models.items():\n",
    "    if scaler:\n",
    "        X_full_train_scaled = scaler.transform(df_train.drop('target', axis=1))\n",
    "    else:\n",
    "        X_full_train_scaled = df_train.drop('target', axis=1)\n",
    "    y_full_train = df_train['target']\n",
    "    X_test_scaled = scaler.transform(df_test.drop('target', axis=1)) if scaler else df_test.drop('target', axis=1)\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    final_metrics = train_evaluate_model(X_full_train_scaled, y_full_train, X_test_scaled, y_test)\n",
    "    final_results[scaler_name] = final_metrics\n",
    "\n",
    "final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': {'accuracy': 0.9664410603496898,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0},\n",
       " 'min_max': {'accuracy': 0.9664410603496898,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0},\n",
       " 'robust': {'accuracy': 0.03355893965031021,\n",
       "  'precision': 0.03355893965031021,\n",
       "  'recall': 1.0,\n",
       "  'f1_score': 0.06493860845839018},\n",
       " 'none': {'accuracy': 0.03355893965031021,\n",
       "  'precision': 0.03355893965031021,\n",
       "  'recall': 1.0,\n",
       "  'f1_score': 0.06493860845839018}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers = {\"standard\": StandardScaler(), \"min_max\": MinMaxScaler(), \"robust\": RobustScaler(), \"none\": None}\n",
    "best_models = {}\n",
    "\n",
    "# Iterowanie przez wszystkie skalery i różne proporcje downsamplingu i podziału zbioru treningowego\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    best_score = 0\n",
    "    for downsample_ratio in [0.5, 1, 2, 3]:\n",
    "        df_train_balanced = prepare_balanced_data(df_train, downsample_ratio)\n",
    "        for split_ratio in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "            X = df_train_balanced.drop('target', axis=1)\n",
    "            y = df_train_balanced['target']\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_ratio, random_state=42)\n",
    "            \n",
    "            # Zdefiniowanie y_test tutaj\n",
    "            y_test = df_test['target']\n",
    "\n",
    "            # Skalowanie danych, jeśli scaler jest zdefiniowany\n",
    "            if scaler:\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                X_test_scaled = scaler.transform(df_test.drop('target', axis=1))\n",
    "            else:\n",
    "                X_train_scaled = X_train\n",
    "                X_val_scaled = X_val\n",
    "                X_test_scaled = df_test.drop('target', axis=1)\n",
    "\n",
    "            # Wybór najlepszej liczby cech przy użyciu RFE\n",
    "            model = LogisticRegression(max_iter=1000)\n",
    "            best_n_features = 0\n",
    "            best_rfe_score = 0\n",
    "            for n_features_to_select in range(1, X_train_scaled.shape[1] + 1):\n",
    "                rfe = RFE(estimator=model, n_features_to_select=n_features_to_select)\n",
    "                rfe.fit(X_train_scaled, y_train)\n",
    "                X_train_rfe = rfe.transform(X_train_scaled)\n",
    "                X_val_rfe = rfe.transform(X_val_scaled)\n",
    "\n",
    "                # Trenowanie i ewaluacja modelu na danych po RFE\n",
    "                model.fit(X_train_rfe, y_train)\n",
    "                y_pred = model.predict(X_val_rfe)\n",
    "                rfe_score = f1_score(y_val, y_pred)  # Wybierz odpowiednią metrykę\n",
    "                if rfe_score > best_rfe_score:\n",
    "                    best_rfe_score = rfe_score\n",
    "                    best_n_features = n_features_to_select\n",
    "\n",
    "            # Trenowanie modelu na pełnym zbiorze treningowym z wybraną liczbą cech\n",
    "            rfe = RFE(estimator=model, n_features_to_select=best_n_features)\n",
    "            rfe.fit(X_train_scaled, y_train)\n",
    "            X_train_rfe = rfe.transform(X_train_scaled)\n",
    "            X_test_rfe = rfe.transform(X_test_scaled)\n",
    "            model.fit(X_train_rfe, y_train)\n",
    "\n",
    "            # Ewaluacja modelu na zbiorze testowym\n",
    "            y_test_pred = model.predict(X_test_rfe)\n",
    "            test_score = f1_score(y_test, y_test_pred)  # Możesz użyć innej metryki, jeśli chcesz\n",
    "\n",
    "            # Zapisanie najlepszego modelu dla danego skalera\n",
    "            if test_score > best_score:\n",
    "                best_score = test_score\n",
    "                best_models[scaler_name] = (model, scaler, downsample_ratio, split_ratio)\n",
    "\n",
    "# Trenowanie najlepszych modeli na pełnych danych treningowych i ocena na zbiorze testowym\n",
    "final_results = {}\n",
    "for scaler_name, (model, scaler, downsample_ratio, split_ratio) in best_models.items():\n",
    "    if scaler:\n",
    "        X_full_train_scaled = scaler.transform(df_train.drop('target', axis=1))\n",
    "        X_test_scaled = scaler.transform(df_test.drop('target', axis=1))\n",
    "    else:\n",
    "        X_full_train_scaled = df_train.drop('target', axis=1)\n",
    "        X_test_scaled = df_test.drop('target', axis=1)\n",
    "\n",
    "    y_full_train = df_train['target']\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    model.fit(X_full_train_scaled, y_full_train)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    final_metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1_score': f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    final_results[scaler_name] = final_metrics\n",
    "\n",
    "final_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
